class Functor f where
    fmap :: (a -> b) -> f a -> f b

fmap takes a function from one type to another and a functor applied with one type
and returns a functor applied with another type.

map :: (a -> b) -> [a] -> [b].

So map is a function that takes a function fro mone type to another and a list of
one type and returns a list of another type. This is a functor! In fact,
map is just a fmap that only works for lists. Here's how list defines its
instance of the Functor typeclass

instance Functor [] where
  fmap = map

Notice how we used [] instead of [a]. Thats because [a] is a concrete type. And
[] is a type constructor. Thats because f must be a type constructor.

Types that act like a box can be functors. You can think of a list as a box that
has an infinite amount of little compartments. So what else acts like a box.

fmap, which has a type of
fmap :: (a -> b) -> f a -> f b.

says give me a function that takes an a and returns a b and a box with an a (or several of them)
inside it and I'll give you a box with a b (or several of them) inside it. It kind of applies the
function to the element inside the box.

Maybe ais like a box that can either hold nothing or hold one item. Here's how
maybe is a functor

instance Functor Maybe where
  fmap f (Just x) = Just (f x)
  fmap f Nothing  = Nothing

Again notice how we use Maybe instead of Maybe a since the former is a type constructor and the later
is a concrete type.

If its an empty value of Nothing then return nothing. If we map over an empty box, we get an empty
box. Just like if we map over an empty list, we get an empty list.

If its ont an empty value, but rather a single value packed up in a Just box, then we apply that
function on the contents of the Just box, and return a Just box that contains the result of applying
that function.

A Tree can also be a functor

instance Functor Tree where
  fmap f (Tree node left right) = Tree (f node) (fmap f left) (fmap f right)
  fmap f EmptyTree = EmptyNode

What about either. Thats a container that contains either right or left.

instance Functor (Either a) where
  fmap f (Right x) = (Right (f x))
  fmap f (Left x) = Left x

Don't be fooled, Either a is still a type consturctor that requires another parameter. Where just
Either is a type constructor that takes two parameters. Remember how Either is defined

data Either a b = Left a | Right b

The reason why we don't apply f to the left type is because f is considered to be an empty type.
Equivalent to Nothing in Maybe.

With the Functor typeclass, we've seen how typeclasses can represent pretty cool higher-order concepts.


We've learned by now how a lot of types (well, type constructors really) are instances of Functor,
like [], Maybe, Either a and a Tree type that we made on our own. We saw how we can map functions
over them for great good. In this section, we'll take a look at two more instances of functor,
namely IO and (->) r.

If some value has a type of, say, IO String, that means that it's an I/O action that, when
performed, will go out into the real world and get some string for us, which it will yield as a result.
We can use <- in do syntax to bind that result to a name. We mentioned that I/O actions are like
boxes with little feet that go out and fetch some value from the outside world for us. We can
inspect what they fetched, but after inspecting, we have to wrap the value back in IO. By thinking
about this box with little feet analogy, we can see how IO acts like a functor.

Let's see how IO is an instance of Functor. When we fmap a function over an I/O action, we want to
get back an I/O action that does the same thing, but has our function applied over its result value.

  instance Functor IO where
      fmap f action = do
          result <- action
          return (f result)

The result of mapping something over an I/O action will be an I/O action. So we use the do
syntax to glue two actions and make a new one. IN the implementation for fmpa, we make a new I/O
action that first performs the original I/O action and stores its result. Then we use the return
keyword, which is a function that makes an I/O action that doesn't do anything, but only presents
something as its result. The action that a do block produces will always have the result value of
its last action. That's why we sue return to make an I/O action that doesn't have any side effects
but still produces an output.

Here's an example of a program w/ I/O actions
  main = do line <- getLine
      let line' = reverse line
      putStrLn $ "You said " ++ line' ++ " backwards!"
      putStrLn $ "Yes, you really said" ++ line' ++ " backwards!"

Here's how it can be wreen w/ fmap
  main = do line <- fmap reverse getLine
      putStrLn $ "You said " ++ line ++ " backwards!"
      putStrLn $ "Yes, you really said" ++ line ++ " backwards!"

Notice how we simply fmap over the getLine I/O action which has a type of IO String, and mapping
reverse over it gives us an I/O action that will go out in the real world, get a line, and then
apply reverse to its result.

Just as we can apply a function to something inside of a Maybe box, we can apply a function to what's
inside an IO box, only the IO box produces some sideeffect.

Another instance of Functor that we've been dealing with all along but didn't know was a Functor is
(->) r. You're probably slightly confused now, since what the heck does (->) r mean? The function
type r -> a can be rewritten as (->) r a, much like we can write '2+3' as '(+) 2 3'.

When we look at it as (->) r a, we can see (->) in a slightly different light, because we see that
its just a type constructor that takes two type parameters, just like Either. But remember, we said
that a type constructor has to take exactly one type parameter in order to be made an instance of
Functor. Thats why we can't make (->) an instance of Functor, but if we partially apply it to
(->) r, it doesn't pose any problems.

We usually mark functions that take anything and return anything as a -> b. r -> a is the same
thing, we just used different letters for the type variables.

  instance Functor ((->) r) where
      fmap f g = (\x -> f (g x))

If the syntax allowed for it, it could have been written as

  instance Functor (r ->) where
      fmap f g = (\x -> f (g x))

But it doesn't, so we have to write it in the former fashion.

First of all, let's think about fmap's type. It's
  fmap :: (a -> b) -> f a -> f b.

So for (->) r, by simply replacing the f's w/ (->) r the type would be
  fmap :: (a -> b) -> ((->) r a) -> ((->) r b)

Now we can infix the (->) operator
  fmap :: (a -> b) -> (r -> a) -> (r -> b)

As you might be able to tell now, this is simply function composition. Looking up the
Functor definition for a function, you will find:
  instance Functor ((->) r) where
      fmap = (.)

Which makes it obvious now that using fmap over functions is just function composition.

So how does the box analogy work here. When we use fmap (+3) over Just 3, its easy to imagine
the Maybe as a box that has some contents on which we apply the (+3) function. But what about
when we're doing fmap (+3) over (+100). You can actually think of (+100) as a box that contains
an eventual result. Sort of like how an I/O action can be thought of as a box that will go out
into the real world and fetch some result.

Using fmap (+3) (+100) will create a new function. The fact that fmap over a function is just
function composition, isn't that useful. But it is very interesting. And allows us to have yet another
example of how fmap works.

If we rewrite fmap with the following syntax instead:
  fmap :: (a -> b) -> (f a -> f b)

which still means the same thing, we can think of fmap as a function that takes a function and returns
a function; rather than thinking of it as a function that takes a function and a functor and returns
another functor.

Taking a function a-> b and returning a function f a -> f b is called a lifting function.

The expression fmap (*2) is a function that takes a functor f over numbers and returns a functor
over numbers. That functor can be a list, a Maybe, an Either String, an I/O action.

When we say a functor over numbers, you can think of that as a functor that has numbers in it. The
former is a bit fancier and more technically correct, but the latter is usually easier to get.

You can think of fmap as either:
    * function that takes a function and a functor and then maps that
      function over the functor to return another functor.
    * OR a function that takes a function and lifts that function so that it operates on functors.

fmap (replicate 3) returns a function w/ the following type definition:
   fmap (replicate 3) :: (Functor f) => f a -> f [a]

This means it will work w/ any functors:
    ghci> fmap (replicate 3) [1,2,3,4]
    => [[1,1,1],[2,2,2],[3,3,3],[4,4,4]]
    ghci> fmap (replicate 3) (Just 4)
    => Just [4,4,4]
    ghci> fmap (replicate 3) (Right "blah")
    => Right ["blah","blah","blah"]
    ghci> fmap (replicate 3) Nothing
    => Nothing
    ghci> fmap (replicate 3) (Left "foo")
    => Left "foo"

In order for something to be a functor, it should satisfy some laws. All functors are expected to
exhibit certain kinds of functor-like properties and behaviors. They should reliably behavor as
things that can be mapped over. Calling fmap on a functor should just map a function over the
functor and nother mor. This is described in the functor laws.


The first functor law states that if we map the id function over a functor, the functor that we get
back should be the same as the original functor.

Lets test this one out on some functors:
    ghci> fmap id (Just 3)
    => Just 3
    ghci> id (Just 3)
    => Just 3
    ghci> fmap id [1..5]
    => [1,2,3,4,5]
    ghci> id [1..5]
    => [1,2,3,4,5]
    ghci> fmap id []
    => []
    ghci> fmap id Nothing
    => Nothing

The second law says that composing two functions and then mapping the resulting function over a
functor should be the same as first mapping one function over the functor and then mapping the other
one.

Formally written it means that
  fmap (f . g) = fmap f . fmap g
OR
  fmap (f . g) F = fmap f . (fmap g F)

If we can show that some type obeys both functor laws, we can rely on it having the same fundamental
behaviors as other functors when it comes to mapping.

Lets examine a case when a type constructor is being labeled as a Functor but is not really a
Functor because it does not satisfy the laws:

  data CMaybe a = CNothing | CJust Int a deriving (Show)

  ghci> CNothing
  => CNothing
  ghci> CJust 0 "haha"
  => CJust 0 "haha"
  ghci> :t CNothing
  => CNothing :: CMaybe a
  ghci> :t CJust 0 "haha"
  => CJust 0 "haha" :: CMaybe [Char]
  ghci> CJust 100 [1,2,3]
  => CJust 100 [1,2,3]

Lets make this an instance of Functor:
  instance Functor CMaybe where
      fmap f CNothing = CNothing
      fmap f (CJust counter x) = CJust (counter+1) (f x)

Because of this definition of fmap, this type constructor does not pass the functor laws because
fmap'ing the id function over it does not return the same Functor (i.e. the counter increase).

If you think of functors as things that output values, you can think of mapping over functors as attaching
a transformation to the output of the functor that changes the value. When we do fmap (+3) [1,2,3],
we attach the transformation (+3) to the output of [1,2,3], so whenever we look at a number that the
list outputs, (+3) will be applied to it.


Applicative functors

In this section, we'll take a look at applicative functors, which are beefed up functors,
represented in Haskell by the Applicative typeclass, found in the Control.Applicative module.

So far, when we were mapping functions over functors, we usually mapped functions that take only one
parameter. But what happens when we map a function that takes 2 parameters over a functor.

  ghci> :t fmap (++) (Just "hey")
  => fmap (++) (Just "hey") :: Maybe ([Char] -> [Char])
  ghci> :t fmap compare (Just 'a')
  => fmap compare (Just 'a') :: Maybe (Char -> Ordering)
  ghci> :t fmap compare "A LIST OF CHARS"
  => fmap compare "A LIST OF CHARS" :: [Char -> Ordering]
  ghci> :t fmap (\x y z -> x + y / z) [3,4,5,6]
  => fmap (\x y z -> x + y / z) [3,4,5,6] :: (Fractional a) => [a -> a -> a]
  ghci> :t fmap (\x -> x "huh") (fmap (++) (Just "hey"))
  => fmap (\x -> x "huh") (fmap (++) (Just "hey")) :: Maybe [Char]
  ghci> fmap (\x -> fmap x (Just "huh")) (fmap (++) (Just "hey"))
  => Just "heyhuh"

We can see how mapping multi-parameter functions over functors returns functors that contain
functions inside their "box". So now what do we do with them? We can map functions that take these
functions as parameters over them as we did in the last example.

But what if we have a functor value of (Just 3 *) and a functor value of Just 5, and we want to map
the function in the first functor over the second funtor. With normal functors we are out of luck.
But we can't map a function that's inside a functor over another functor with what fmap offers us.

We could pattern match the function out of the functor or pattern match the result:
  ghci> fmap (\x -> fmap x (Just 5)) (Just (3 *))
  => Just (Just 15)

This is where the Applicative typeclass comes in to play. Its from the Control.Applicative module
and defines two methods, pure and <*>. It doesn't proivide a default implementation for any of them
so we have to define them both if we want something to be an applicative functor. The class is defined like so:

class (Functor f) => Applicative f where
    pure :: a -> f a
    (<*>) :: f (a -> b) -> f a -> f b

The first method, pure, has a type declaration of :: a -> f a. f plays the role of our applicative
functor instance here. We can tell a lot through this type declaration; pure should take a value
of any type and return an applicative functor with that value inside of it. When we say 'inside' of
it, we're using the box analogy again, even though we've seen that it doesn't always stand up to
scrutiny. Thus, pure, takes a value and wraps it in an applicative functor that has that value
as the result inside it.

A better way of thinking about pure would be to say that it takes a valueand puts it in some sort
of default (or pure) context - a minimal context that still yields that value.

The <*> function is really interesting. Its type definition certainly reminds us of fmap. Its sort
of a beefed up fmap. Whereas fmap takes a function and a functor and applies the function inside
the functor, <*> takes a functor that has a function in it and another functor and sort of extracts
that function from the first functor, and then maps it over the second one.

Lets take a look at the Applicative instance implementation for Maybe

instance (Maybe a) where
  pure = Just
  Nothing <*> _ = Nothing
  (Just f) <*> something = fmap f something

Our implementation, because of partial application, for pure is equivalent to pure a = Just a.

For <*>, we can't extract a function out of Nothing, because it has no function inside of it. So
there we return Nothing. If the first parameter is Just with some function inside of it, we say
then that we want to map that function over the second parameter. Don't have to worry about the
right hand being Nothing because fmap over Nothing is still Nothing.

  ghci> Just (+3) <*> Just 9
  => Just 12
  ghci> Just (++"hahah") <*> Nothing
  => Nothing
  ghci> Nothing <*> Just "woot"
  => Nothing

This case makes sense. Breaking this down we have
  x :: f a->b
  b :: f a

  x <*> b :: f b

We can use pure to do similar things. first lets look at some basic usage of pure

  ghci> :t pure (+3)
  => pure (+3) :: (Applicative f, Num a) => f (a -> a)
  ghci> :t (pure (+3)) Just
  => (pure (+3)) Just :: Num a => a -> a
  ghci> :t ((pure (+3)) Just) 13
  => ((pure (+3)) Just) 13 :: Num t => t
  ghci> ((pure (+3)) Just) 13
  => 16

Lets break this down. First we call pure on our function (+3). This simply puts the function
inside a default context. Which essentially transforms it into an instance of a functor.

We then apply another argument, Just, to our functor (remember Just is an instance of Applicative):
  :: (Applicative f, Num a) => f (a -> a)
which transforms it to
  :: Num a => (a -> a)
which is just a function taking a single arg. Finally we just apply our numeric arg to that function
to get our numeric result.

So now lets look at how pure can be used in the context of our lift function:
  ghci> pure (+3) <*> Just 10
  => Just 13
  ghci> fmap (+3) (Just 10
  => Just 13
  ghci> pure (+4) <*> Right 14
  => Right 18
  ghci> pure (+4) <*> Left "hey"
  => Left "hey"
  ghci> pure (+3) <*> Just 9
  => Just 12

We can see that pure (a -> a) <*> (Just a) == fmap (a -> a) (Just a)

pure is just putting our function in a Functor so that it can be lifted out and operated on over
our value in the Just Functor.

With normal functors, you can just mmap a function over a functor and then you can't get the result
out in any general way, even if the result is a partially applied function. Applicative functors,
on the other hand, allow you to operatee on severl functors with a single function. Check this out:

  ghci> pure (+) <*> Just 3 <*> Just 5
  => Just 8
  ghci> pure (+) <*> Just 3 <*> Nothing
  Nothing
  ghci> pure (+) <*> Nothing <*> Just 5
  Nothing

So cool! We used the applicative operator to partially apply a function and then used the operator
again to fully apply the function and cause it to resolve into our 'box'.

Applicative functors and the applicative style of doing pure f <*> x <*> y <*> ... allows us to take
a function that expects parameters that aren't necessarily wrapped in functors and use that function
to operate on several values that are in functor contexts.

This becomes even more handy when we consider the fact that 'pure f <*> x' equals 'fmap f x'. This
is in fact one of the applicative laws. Think about this concept. Like we said, pure puts a value
in a default context. If we just put a function in a default context and then extract and apply it
to a value inside another applicative functor, we did the same thing as mapping that function over
the applicative functor.

This means that 'pure f <*> x <*> y <*> ...' turns into 'fmap f x <*> y <*> ...'. This is why
Control.Applicative exports a function <$>, which is just fmap as an infix operator. here's how
its defined:
  (<$>) :: (Functor f) => (a -> b) -> f a -> f b
  f <$> x = fmap f x

By using <$>, the applicative style really shines, because now if we want to apply a function f
between three applicative functors, we can write f <$> x <*> y <*> z. If the parameters weren't
applicative functors but normal values, we'd write f x y z.

Look at the following example:

  ghci> (++) <$> Just "johntra" <*> Just "volta"
  => Just "johntravolta"

Awesome! To use a normal function on applicative functors, just sprinkle some <$> and <*> about and
the function will operate on applicatives and return an applicative


So far, we've only used Maybe in our examples and you might be thinking that applicative functors
are all about Maybe. There are loads of other instances of Applicative, so let's go and meet them!

Lists (actually the list type constructor, []) are applicative functors. What a suprise! Here's how
[] is an instance of Applicative:

  instance Applicative [] where
      pure x = [x]
      fs <*> xs = [f x | f <- fs, x <- xs]

Earlier, we said that pure takes a value and puts it in a default context. Or in other words, a
minimal context that still yields that value. The minimal context for lists would be the empty list,
[], but the empty list represents the lack of a value, so it can't hold in itself the value that we
used pure on. That's why pure takes a value and puts it in a singleton list. Similarly,
the minimal context for the Maybe applicative functor would be a Nothing.

  ghci> pure "Hey" :: [String]
  => ["Hey"]
  ghci> pure "Hey" :: Maybe String
  => Just "Hey"

What do wee think the type of <*> if it were limited only to lists:
  [a -> b] -> [a] -> [b]

But the thing here is that the left list can have zero functions, one function, or several functions
inside it. The right list can also hold several values.

  ghci> [(*0),(+100),(^2)] <*> [1,2,3]
  => [0,0,0,101,102,103,1,4,9]

The left list has three functions and the right list has three values, so the resulting list will
have nine elements. Every function in the left list is applied to every function in the right one.
If we have a list of functions that take two parameters, we can apply those functions between two
lists.

  ghci> [(+),(*)] <*> [1,2] <*> [3,4]
  => [4,5,5,6,3,4,6,8]
  ghci> (++) <$> ["ha","heh","hmm"] <*> ["?","!","."]
  => ["ha?","ha!","ha.","heh?","heh!","heh.","hmm?","hmm!","hmm."]

Again, see how we used a normal function that takes two strings between two applicative functors of
strings just by inserting the appropriate applicative operators.

Using the applicative style on lists is often a good replacement for list comprehensions
  ghci> [ x*y | x <- [2,5,10], y <- [8,10,11]]
  => [16,20,22,40,50,55,80,100,110]
  ghci> fmap (*) [2,5,10] <*> [8,10,11]
  => [16,20,22,40,50,55,80,100,110]
  ghci> (*) <$> [2,5,10] <*> [8,10,11]
  => [16,20,22,40,50,55,80,100,110]
  ghci> [(*)] <*> [2,5,10] <*> [8,10,11]
  => [16,20,22,40,50,55,80,100,110]
  ghci> pure (*) <*> [2,5,10] <*> [8,10,11]
  => [16,20,22,40,50,55,80,100,110]

It's easy to see how
  (pure f <*> xs) == (fmap f xs)
with lists. pure f == [f] and
  [f] <*> xs
will apply every function in the left list to every value in the right one, but there's just one function in the left list, so it's like mapping.


Another instance of Applicative that we've already encountered is IO. This is how the instance is implemented:

  instance Applicative IO where
      pure = return
      a <*> b = do
          f <- a
          x <- b
          return (f x)

Since pure is all about putting a value in a minimal context that still holds it as its result, it
makes sense that pure is just return, because return does exactly that; it makes an I/O action that
doesn't do anything, it just yields some value as its result, but it doesn't really do any I/O
operations like printing to the terminal or reading from a file.

If <*> were specialized for IO it would have a type of
  (<*>) :: IO (a -> b) -> IO a -> IO b

It would take an I/O action that yields a function as its result and another I/O action and create
a new I/O action from those two that, when performed, first performs the first one to get the
function and then performs the second one to get the value and then it would yield that function
applied to the value as its result. We used do syntax to implement it here. Remember, do syntax is
about taking several I/O actions and gluing them into one, which is exactly what we do here.

With Maybe and [], we could think of <*> as simply extracting a function from its left parameter and
then sort of applying it over the right one. With IO, extracting is still in the game, but now we
also have a notion of sequencing, because we're taking two I/O actions and we're sequencing, or
gluing, them into one. We have to extract the function from the first I/O action, but to extract a
result from an I/O action, it has to be performed.

To get two characters from stdin and concatonate them, you might do this without applicative
functors:
  myAction :: IO String
  myAction = do
      a <- getLine
      b <- getLine
      return $ a ++ b

Using applicative functors, you could instead:
  ghci> pure (++) <*> getLine <*> getLine
OR
  ghci> (++) $ getLine <*> getLine

Remember, getLine is an I/O action with the type getLine :: IO String. When we use <*> between two
applicative functors, the result is an applicative functor, so this all makes sense.

The type of the expression (++) <$> getLine <*> getLine is IO String, which means that this
expression is a completely normal I/O action like any other, which also holds a result value inside
it, just like other I/O actions. That's why we can do stuff like:
  main = do
      a <- (++) <$> getLine <*> getLine
      putStrLn $ "The two lines concatenated turn out to be: " ++ a



Another instance of Applicative is (->) r, so functions. They are rarely used with the applicative
style outside of code golf, but they're still interesting as applicatives, so let's take a look at
how the function instance is implemented.

  instance Applicative ((->) r) where
    pure x = (\_ -> x)
    f <*> g = \x -> f x (g x)

When we wrap a value into an applicative functor with pure, the result it yields always has to be
that value. A minimal default context that still yields that value as a result. That's why in the
function instance implementation, pure takes a value and creates a function that ignores its
parameter and always returns that value. If we look at the type for pure, but specialized for the
(->) r instance, it's pure :: a -> (r -> a).

  ghci> (pure 3) "blah"
  => 3

Because of currying, function application is left-associative, so we can omit the parentheses.

  ghci> pure 3 "blah"
  => 3


The instance implementation for <*> is a bit cryptic, so it's best if we just take a look at how to
use functions as applicative functors in the applicative style.

  ghci> :t (+) <$> (+3) <*> (*100)
  => (+) <$> (+3) <*> (*100) :: (Num a) => a -> a
  ghci> (+) <$> (+3) <*> (*100) $ 5
  => 508

Calling <*> with two applicative functors results in an applicative functor, so if we use it on two
functions, we get back a function. So what goes on here? When we do (+) <$> (+3) <*> (*100), we're
making a function that will use + on the results of (+3) and (*100) and return that.

To demonstrate on a real example, when we did
  (+) <$> (+3) <*> (*100) $ 5
the 5 first got applied to (+3) and (*100), resulting in 8 and 500. Then, + gets called with 8 and
500, resulting in 508.

You can think of functions as boxes that contain their eventual results, so doing k <$> f <*> g
creates a function that will call k with the eventual results from f and g.

When we do something like (+) <$> Just 3 <*> Just 5, we're using + on values that might or might not
be there, which also results in a value that might or might not be there.

When we do (+) <$> (+10) <*> (+5), we're using + on the future return values of (+10) and (+5) and
the result is also something that will produce a value only when called with a parameter.

We don't often use functions as applicatives, but this is still really interesting. It's not very
important that you get how the (->) r instance for Applicative works, so don't despair if you're not
getting this right now.


Control.Applicative defines a function that's called liftA2, which has a type of
liftA2 :: (Applicative f) => (a -> b -> c) -> f a -> f b -> f c .

It's defined like this:

liftA2 :: (Applicative f) => (a -> b -> c) -> f a -> f b -> f c
liftA2 f a b = f <$> a <*> b

Nothing special, it just applies a function between two applicatives, hiding the applicative style
that we've become familiar with. The reason we're looking at it is because it clearly showcases why
applicative functors are more powerful than just ordinary functors. With ordinary functors, we can
just map functions over one functor. But with applicative functors, we can apply a function between
several functors.

It's also interesting to look at this function's type as (a -> b -> c) -> (f a -> f b -> f c). When
we look at it like this, we can say that liftA2 takes a normal binary function and promotes it to a
function that operates on two functors.


Here's an interesting concept: we can take two applicative functors and combine them into one
applicative functor that has inside it the results of those two applicative functors in a list. For
instance, we have Just 3 and Just 4. Let's assume that the second one has a singleton list inside
it, because that's really easy to achieve:

  ghci> fmap (\x -> [x]) (Just 4)
  => Just [4]

OK, so let's say we have Just 3 and Just [4]. How do we get Just [3,4]? Easy.
  ghci> liftA2 (:) (Just 3) (Just [4])
  => Just [3,4]
  ghci> (:) <$> Just 3 <*> Just [4]
  => Just [3,4]

Remember, : is a function that takes an element and a list and returns a new list with that element
at the beginning. Now that we have Just [3,4], could we combine that with Just 2 to produce
Just [2,3,4]? Of course we could. It seems that we can combine any amount of applicatives into one
applicative that has a list of the results of those applicatives inside it.

In conclusion, applicative functors aren't just interesting, they're also useful, because they allow
us to combine different computations, such as I/O computations, non-deterministic computations,
computations that might have failed, etc. by using the applicative style. Just by using <$> and <*>
we can use normal functions to uniformly operate on any number of applicative functors and take
advantage of the semantics of each one.




The newtype keyword

So far, we've learned how to make our own algebraic data types by using the data keyword. We've
also learned how to give existing types synonyms with the type keyword. In this section, we'll be
taking a look at how to make new types out of existing data types by using the newtype keyword and
why we'd want to do that in the first place.

Think about how we might write the data declaration for our ZipList a type. One way would be to do
it like so:

data ZipList a = ZipList [a]

A type that has just one value constructor and that value constructor has just one field that is a
list of things. We might also want to use record syntax so that we automatically get a function that
extracts a list from a ZipList:

data ZipList a = ZipList { getZipList :: [a] }

The newtype keyword in Haskell is made exactly for these cases when we want to just take one type
and wrap it in something to present it as another type. In the actual libraries, ZipList a is
defined like this:

newtype ZipList a = ZipList { getZipList :: [a] }

Instead of the data keyword, the newtype keyword is used. Now why is that? Well for one, newtype is
faster. If you use the data keyword to wrap a type, there's some overhead to all that wrapping and
unwrapping when your program is running. But if you use newtype, Haskell knows that you're just
using it to wrap an existing type into a new type (hence the name), because you want it to be the
same internally but have a different type. With that in mind, Haskell can get rid of the wrapping
and unwrapping once it resolves which value is of what type.


So why not just use newtype all the time instead of data then? Well, when you make a new type from
an existing type by using the newtype keyword, you can only have one value constructor and that
value constructor can only have one field. But with data, you can make data types that have several
value constructors and each constructor can have zero or more fields:

data Profession = Fighter | Archer | Accountant
data Race = Human | Elf | Orc | Goblin
data PlayerCharacter = PlayerCharacter Race Profession

When using newtype, you're restricted to just one constructor with one field.


We can also use the deriving keyword with newtype just like we would with data. We can derive
instances for Eq, Ord, Enum, Bounded, Show and Read. If we derive the instance for a type class,
the type that we're wrapping has to be in that type class to begin with. It makes sense, because
newtype just wraps an existing type. So now if we do the following, we can print and equate values
of our new type:

newtype CharList = CharList { getCharList :: [Char] } deriving (Eq, Show)

Let's give that a go:

  ghci> CharList "this will be shown!"
  => CharList {getCharList = "this will be shown!"}
  ghci> CharList "benny" == CharList "benny"
  => True
  ghci> CharList "benny" == CharList "oisters"
  => False

In this particular newtype, the value constructor has the following type:

CharList :: [Char] -> CharList

The getCharList function, which was generated for us because we used record syntax in our newtype,
has this type:

getCharList :: CharList -> [Char]

It takes a CharList value and converts it to a [Char] value. You can think of this as wrapping and
unwrapping, but you can also think of it as converting values from one type to the other.

We mentioned that newtype is usually faster than data. The only thing that can be done with newtype
is turning an existing type into a new type, so internally, Haskell can represent the values of
types defined with newtype just like the original ones, only it has to keep in mind that the their
types are now distinct. This fact means that not only is newtype faster, it's also lazier. Let's
take a look at what this means.

Like we've said before, Haskell is lazy by default, which means that only when we try to actually
print the results of our functions will any computation take place. Furthemore, only those
computations that are necessary for our function to tell us the result will get carried out.

The undefined value in Haskell represents an erronous computation. If we try to evaluate it
(that is, force Haskell to actually compute it) by printing it to the terminal, Haskell will throw
a hissy fit (technically referred to as an exception):

  ghci> undefined
  => *** Exception: Prelude.undefined

However, if we make a list that has some undefined values in it but request only the head of the list, which is not undefined, everything will go smoothly because Haskell doesn't really need to evaluate any other elements in a list if we only want to see what the first element is:

  ghci> head [3,4,5,undefined,2,undefined]
  => 3

This difference in behavior may seem trivial, but it's actually pretty important because it helps us
realize that even though types defined with data and newtype behave similarly from the programmer's
point of view because they both have value constructors and fields, they are actually two different
mechanisms. Whereas data can be used to make your own types from scratch, newtype is for making a
completely new type out of an existing type. Pattern matching on newtype values isn't like taking
something out of a box (like it is with data), it's more about making a direct conversion from one
type to another.

At this point, you may be a bit confused about what exactly the difference between type, data and
newtype is, so let's refresh our memory a bit.

The type keyword is for making type synonyms. What that means is that we just give another name to
an already existing type so that the type is easier to refer to. Say we did the following:

type IntList = [Int]

All this does is to allow us to refer to the [Int] type as IntList. They can be used
interchangeably. We don't get an IntList value constructor or anything like that. Because [Int] and
IntList are only two ways to refer to the same type, it doesn't matter which name we use in our
type annotations:

  ghci> ([1,2,3] :: IntList) ++ ([1,2,3] :: [Int])
  => [1,2,3,1,2,3]

We use type synonyms when we want to make our type signatures more descriptive by giving types names
that tell us something about their purpose in the context of the functions where they're being used.
For instance, when we used an association list of type [(String,String)] to represent a phone book,
we gave it the type synonym of PhoneBook so that the type signatures of our functions were easier to
read.

The newtype keyword is for taking existing types and wrapping them in new types, mostly so that it's
easier to make them instances of certain type classes. When we use newtype to wrap an existing type,
the type that we get is separate from the original type.

When we use record syntax in our newtype declarations, we get functions for converting between the
new type and the original type: namely the value constructor of our newtype and the function for
extracting the value in its field. The new type also isn't automatically made an instance of the
type classes that the original type belongs to, so we have to derive or manually write them.

In practice, you can think of newtype declarations as data declarations that can only have one
constructor and one field. If you catch yourself writing such a data declaration, consider using
newtype.

The data keyword is for making your own data types and with them, you can go hog wild. They can
have as many constructors and fields as you wish and can be used to implement any algebraic data
type by yourself. Everything from lists and Maybe-like types to trees.

If you just want your type signatures to look cleaner and be more descriptive, you probably want
type synonyms. If you want to take an existing type and wrap it in a new type in order to make it an
instance of a type class, chances are you're looking for a newtype. And if you want to make
something completely new, odds are good that you're looking for the data keyword.




Monoids

Type classes in Haskell are used to present an interface for types that have some behavior in
common. We started out with simple type classes like Eq, which is for types whose values can be
equated, and Ord, which is for things that can be put in an order and then moved on to more
interesting ones, like Functor and Applicative.

When we make a type, we think about which behaviors it supports, i.e. what it can act like and then
based on that we decide which type classes to make it an instance of. If it makes sense for values
of our type to be equated, we make it an instance of the Eq type class. If we see that our type is
some kind of functor, we make it an instance of Functor, and so on.

Now consider the following: * is a function that takes two numbers and multiplies them. If we
multiply some number with a 1, the result is always equal to that number. It doesn't matter if we
do 1 * x or x * 1, the result is always x. Similarly, ++ is also a function which takes two things
and returns a third. Only instead of multiplying numbers, it takes two lists and concatenates them.
And much like *, it also has a certain value which doesn't change the other one when used with ++.
That value is the empty list: [].

  ghci> 4 * 1
  => 4
  ghci> 1 * 9
  => 9
  ghci> [1,2,3] ++ []
  => [1,2,3]
  ghci> [] ++ [0.5, 2.5]
  => [0.5,2.5]

It seems that both * together with 1 and ++ along with [] share some common properties:

  The function takes two parameters.
  The parameters and the returned value have the same type.
  There exists such a value that doesn't change other values when used with the binary function.

There's another thing that these two operations have in common that may not be as obvious as our
previous observations: when we have three or more values and we want to use the binary function to
reduce them to a single result, the order in which we apply the binary function to the values
doesn't matter.

  ghci> (3 * 2) * (8 * 5)
  => 240
  ghci> 3 * (2 * (8 * 5))
  => 240
  ghci> "la" ++ ("di" ++ "da")
  => "ladida"
  ghci> ("la" ++ "di") ++ "da"
  => "ladida"

We call this property associativity. * is associative, and so is ++, but -, for example, is not.
The expressions (5 - 3) - 4 and 5 - (3 - 4) result in different numbers.

By noticing and writing down these properties, we have chanced upon monoids! A monoid is when you
have an associative binary function and a value which acts as an identity with respect to that
function.

When something acts as an identity with respect to a function, it means that when called with that
function and some other value, the result is always equal to that other value. 1 is the identity
with respect to * and [] is the identity with respect to ++.

There are a lot of other monoids to be found in the world of Haskell, which is why the Monoid type
class exists. It's for types which can act like monoids. Let's see how the type class is defined:

class Monoid m where
    mempty :: m
    mappend :: m -> m -> m
    mconcat :: [m] -> m
    mconcat = foldr mappend mempty

The Monoid type class is defined in import Data.Monoid. Let's take some time and get properly
acquainted with it.

First of all, we see that only concrete types can be made instances of Monoid, because the m in the
type class definition doesn't take any type parameters. This is different from Functor and
Applicative, which require their instances to be type constructors which take one parameter.

The first function is mempty. It's not really a function, since it doesn't take parameters, so it's
a polymorphic constant, kind of like minBound from Bounded. mempty represents the identity value for
a particular monoid.

Next up, we have mappend, which, as you've probably guessed, is the binary function. It takes two
values of the same type and returns a value of that type as well. It's worth noting that the
decision to name mappend as it's named was kind of unfortunate, because it implies that we're
appending two things in some way. While ++ does take two lists and append one to the other, *
doesn't really do any appending, it just multiplies two numbers together. When we meet other
instances of Monoid, we'll see that most of them don't append values either, so avoid thinking in
terms of appending and just think in terms of mappend being a binary function that takes two monoid
values and returns a third.

Before moving on to specific instances of Monoid, let's take a brief look at the monoid laws. We
mentioned that there has to be a value that acts as the identity with respect to the binary function
and that the binary function has to be associative. It's possible to make instances of Monoid that
don't follow these rules, but such instances are of no use to anyone because when using the Monoid
type class, we rely on its instances acting like monoids. Otherwise, what's the point? That's why
when making instances, we have to make sure they follow these laws:

  mempty `mappend` x = x
  x `mappend` mempty = x
  (x `mappend` y) `mappend` z = x `mappend` (y `mappend` z)

The first two state that mempty has to act as the identity with respect to mappend and the third
says that mappend has to be associative i.e. that it the order in which we use mappend to reduce
several monoid values into one doesn't matter. Haskell doesn't enforce these laws, so we as the
programmer have to be careful that our instances do indeed obey them.

Lists are monoids

Yes, lists are monoids! Like we've seen, the ++ function and the empty list [] form a monoid. The
instance is very simple:

instance Monoid [a] where
    mempty = []
    mappend = (++)

  ghci> [1,2,3] `mappend` [4,5,6]
  => [1,2,3,4,5,6]
  ghci> mconcat [[1,2],[3,6],[9]]
  => [1,2,3,6,9]
  ghci> mempty :: [a]
  => []

One of the more interesting ways to put monoids to work is to make them help us define folds over
various data structures. So far, we've only done folds over lists, but lists aren't the only data
structure that can be folded over. We can define folds over almost any data structure. Trees
especially lend themselves well to folding.

Because there are so many data structures that work nicely with folds, the Foldable type class was
introduced. Much like Functor is for things that can be mapped over, Foldable is for things that
can be folded up!

import qualified Foldable as F

TAlright, so what are some of the functions that this type class defines? Well, among them are
foldr, foldl, foldr1 and foldl1. Huh? But we already know these functions, what's so new about this?
Let's compare the types of Foldable's foldr and the foldr from the Prelude to see how they differ:

  ghci> :t foldr
  => foldr :: (a -> b -> b) -> b -> [a] -> b
  ghci> :t F.foldr
  => F.foldr :: (F.Foldable t) => (a -> b -> b) -> b -> t a -> b

Ah! So whereas foldr takes a list and folds it up, the foldr from Data.Foldable accepts any type
that can be folded up, not just lists! As expected, both foldr functions do the same for lists:

  ghci> foldr (*) 1 [1,2,3]
  => 6
  => ghci> F.foldr (*) 1 [1,2,3]
  => 6

Okay then, what are some other data structures that support folds? Well, there's the Maybe we all 
know and love!

  ghci> F.foldl (+) 2 (Just 9)
  => 11
  ghci> F.foldr (||) False (Just True)
  => True

But folding over a Maybe value isn't terribly interesting, because when it comes to folding, it 
just acts like a list with one element if it's a Just value and as an empty list if it's Nothing. So
let's examine a data structure that's a little more complex then.
